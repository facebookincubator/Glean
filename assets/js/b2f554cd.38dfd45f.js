"use strict";(self.webpackChunkwebsite=self.webpackChunkwebsite||[]).push([[5894],{76042:e=>{e.exports=JSON.parse('{"blogPosts":[{"id":"incremental","metadata":{"permalink":"/blog/incremental","source":"@site/blog/2022-12-01-incremental.md","title":"Incremental indexing with Glean","description":"This post describes how Glean supports incremental indexing of","date":"2022-12-01T00:00:00.000Z","formattedDate":"December 1, 2022","tags":[{"label":"glean","permalink":"/blog/tags/glean"},{"label":"incremental","permalink":"/blog/tags/incremental"}],"readingTime":7.075,"hasTruncateMarker":false,"authors":[{"name":"Simon Marlow","title":"Simon Marlow","url":"https://simonmar.github.io/","imageURL":"http://simonmar.github.io/images/simonmarlow.jpg"}],"frontMatter":{"slug":"incremental","title":"Incremental indexing with Glean","author":"Simon Marlow","author_title":"Simon Marlow","author_url":"https://simonmar.github.io/","author_image_url":"http://simonmar.github.io/images/simonmarlow.jpg","tags":["glean","incremental"]}},"content":"import {SrcFile,SrcFileLink} from \'@site/utils\';\\n\\n\\n  This post describes how Glean supports *incremental indexing* of\\n  source code, to maintain an up-to-date index of a large repository\\n  using minimal resources. This is an overview of the problems and\\n  some aspects of how we solved them; for the technical details of the\\n  implementation see [Implementation Notes:\\n  Incrementality](/docs/implementation/incrementality).\\n\\n## Background\\n\\nIndexing a large amount of source code can take a long time. It\'s not\\nuncommon for very large indexing jobs to take multple\\nhours. Furthermore, a monolithic indexing job produces a large DB that\\ncan be slow to ship around, for example to replicate across a fleet of\\nGlean servers.\\n\\nSource code changes often, and we would like to keep the index up to\\ndate, but redoing the monolithic indexing job for every change is out\\nof the question. Instead what we would like to do is to update a\\nmonolithic index with the *changes* between the base revision and the\\ncurrent revision, which should hopefully be faster than a full\\nrepository indexing job because we only have to look at the things\\nthat have changed. The goal is to be able to index the changes in\\n*O(changes)* rather than *O(repository)*, or as close to that as we\\ncan get.\\n\\n## How incrementality works\\n\\nTo produce a modified DB, we hide a portion of the data in the\\noriginal DB, and then stack a DB with the new data on top. Like this:\\n\\n![Incremental stack](./incremental/stack.jpg)\\n\\nThe user asks for the DB \\"new\\", and they can then work with the data\\nin exactly the same way as they would for a single DB. The fact that\\nthe DB is a stack is invisible to a user making queries. Furthermore,\\nthe DB \\"old\\" still exists and can be used simultaneously, giving us\\naccess to multiple versions of the DB at the same time. We can even\\nhave many different versions of \\"new\\", each replacing a different\\nportion of \\"old\\".\\n\\nAll of the interesting stuff is in how we hide part of the data in the\\nold DB.  How do we hide part of the data?\\n\\nWhen facts are added to a Glean DB, the producer of the facts can\\nlabel facts with a *unit*. A unit is just a string; Glean doesn\'t impose\\nany particular meaning on units so the indexer can use whatever\\nconvention it likes, but typically a unit might be a filename or\\nmodule name. For example, when indexing a file F, the indexer would\\nlabel all the facts it produces with the unit F.\\n\\nTo hide some of the data in a DB, we specify which units to exclude\\nfrom the base DB, like this:\\n\\n```\\nglean create --repo <new> --incremental <old> --exclude A,B,C\\n```\\n\\nwould create a DB `<new>` that stacks on top of `<old>`, hiding units A, B\\nand C.\\n\\nSo to index some code incrementally, we would first decide which files\\nneed to be reindexed, create an incremental DB that hides those files\\nfrom the base DB and then add the new facts.\\n\\nTo implement hiding correctly, Glean has to remember which facts are\\nowned by which units. But it\'s not quite that simple, because facts\\ncan refer to each other, and the DB contents must be valid (which has\\na formal definition but informally means \\"no dangling\\nreferences\\"). For example, if we have facts **x** and **y**, where **x** refers to\\n**y**:\\n\\n![Fact dependency](./incremental/factdep1.jpg)\\n\\nand we hide unit B, then **y** must still be visible, otherwise the\\nreference from **x** would be dangling and the DB would not be valid.\\n\\nSo after the indexer has finished producing facts, Glean propagates\\nall the units through the graph of facts, resulting in a mapping from\\nfacts to **ownership sets**.\\n\\n![Fact dependency with ownership sets](./incremental/factdep2.jpg)\\n\\nIt turns out that while there are lots of facts, there are relatively\\nfew distinct ownership sets. Furthermore, facts produced together tend\\nto have the same ownership set, and we can use this to store the\\nmapping from facts to ownership sets efficiently. To summarise:\\n\\n\\n* Ownership sets are assigned unique IDs and stored in the DB using <a href=\\"https://github.com/facebook/folly/blob/main/folly/experimental/EliasFanoCoding.h\\">Elias Fano Coding</a>\\n* The mapping from facts to ownership sets is\\n  stored as an interval map\\n\\nAs a result, keeping all this information only adds about 7% to the DB\\nsize.\\n\\n### What about derived facts?\\n\\nDerived facts must also have ownership sets, because we have to know\\nwhich derived facts to hide. When is a derived fact visible? When all\\nof the facts that it was derived from are visible.\\n\\nFor example, if we have a fact **r** that was derived from **p** and **q**:\\n\\n![Derived fact](./incremental/derived.jpg)\\n\\nThe ownership set of **r** is `{ P } & { Q }`, indicating that it should be\\nvisible if both P and Q are visible. Note that facts might be derived\\nfrom other derived facts, so these ownership expressions can get\\narbitrarily large. Normalising them to disjunctive normal form would\\nbe possible, but we haven\'t found that to be necessary so far.\\n\\n### Performance\\n\\nThere are three aspects to performance:\\n\\n* **Indexing performance**. We measured the impact of computing\\n ownership at indexing time to be 2-3% for Python, for Hack it was in\\n the noise, and we don\'t\\n expect other languages to be significantly different.\\n* **Query performance**. Initially query performance for an\\n incremental stack was much slower because we have to calculate the visibility of every fact discovered during a query. However, with some [caching optimisations](/docs/implementation/incrementality#caching-fact-ownership) we were able to get the overhead to less than 10% for \\"typical\\" queries, of the kind that Glass does. Queries that do a lot of searching may be impacted by around 3x, but these are not typically found in production use cases.\\n* **Incremental derivation performance**. We would like derivation in the incremental DB to take time proportional to the number of facts in the increment. We implemented incremental derivation for some kinds of query; optimising queries to achieve this in general is a hard problem that we\'ll return to probably next year.\\n\\n### Stacked incremental DBs\\n\\nSo far we have only been considering how to stack a single increment\\non top of a base DB. What if we want to create deeper stacks?\\n\\n![Stacked incremental database](./incremental/stacked-incremental.jpg)\\n\\nThe DB \\"newer\\" stacks on top of \\"new\\", and hides some more units. So\\nthere are now portions of both \\"new\\" and \\"old\\" that need to be hidden\\n(the darker grey boxes), in addition to the original portion of \\"old\\"\\nthat we hid (light grey box).\\n\\nAs before, we might have multiple versions of \\"newer\\" stacked on top\\nof the same \\"new\\", and in general these DB stacks form a tree. All the\\nintermediate nodes of the tree are usable simultaneously: no data is\\nbeing modified, only shared and viewed differently depending on which\\nnode we choose as the top of our stack.\\n\\nOne interesting aspect that arises when we consider how to track\\nownership of facts in this model is fact dependencies across the\\nboundaries between DBs.  For instance, suppose we have\\n\\n![Stacked dependency](./incremental/stacked-dependency.jpg)\\n\\nIf we hide B, then considering the ownership data for \\"old\\" alone\\nwould tell us that y is invisible. But we must make it visible,\\nbecause x depends on it. So when computing the ownership data for\\n\\"new\\", we have to transitively propagate ownership to facts in the\\nbase DB(s), store that in \\"new\\", and consult it when deciding which\\nfacts in \\"old\\" are visible.\\n\\n### Derived facts in stacked incremental DBs\\n\\nA fact might be derived from multiple facts in different DBs in the\\nstack, and we have to represent its ownership correctly. Therefore\\n\\n* There must be a single namespace of ownership sets for the whole DB stack. That is, stacked DBs add more sets. (or else we copy ownership sets from the base DB, which doesn\'t seem attractive).\\n* Since a fact may be owned multiple different ways (see previous section) we have to take this into account when computing the ownership expression for a derived fact.\\n\\nThis is the most complex diagram in the post (phew!):\\n\\n![Stacked derived](./incremental/stacked-derived.jpg)\\n\\nHere the dashed arrow means \\"derived from\\" and the solid arrow means\\n\\"refers to\\".\\n\\nThe fact **d** should be visible if both **x** and **y** are visible. The\\nownership of **x** is `{A}` and **y** is `{B,C}` (because it is referred to from **z**\\nwhich has owner B), so the final owner of **d** is `{A} && {B,C}`.\\n\\nTracking all this shouldn\'t be too expensive, but it\'s tricky to get\\nright!"}]}')}}]);